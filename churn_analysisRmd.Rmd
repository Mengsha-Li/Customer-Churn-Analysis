---
title: "401FinalReport"
author: "Maxine Li"
date: "12/4/2019"
output: pdf_document
---

```{r setup, include=FALSE}
library(readxl)
library(lattice)
library(ggplot2)
library(caret)
library(reshape2)
library(dplyr)
library(tidyverse)
library(janitor)
library(car)
library(stargazer)
library(knitr)
```

```{r}
# separate train and test data
data <- read_xlsx("401final.xlsx")
data <- data[,-c(1)] # delete first column
data <- na.omit(data)

```

# correlation map
```{r}
cortrain <- round(cor(data1),2)
melted_cortrain <- melt(cortrain, na.rm = TRUE)

ggplot(data = melted_cortrain, aes(Var2, Var1, fill = value))+
 geom_tile(color = "white")+
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Pearson\nCorrelation") + 
  theme_minimal()+ 
  theme(axis.text.x = element_text(angle = 315, size = 4, hjust = 0))+
  coord_fixed()

```

```{r}
glimpse(data)
```

# Spliting dataset
```{r}
data1 <- data[,c(2,4,10,11,13,16:18,21,24:26,28)]

intrain <- createDataPartition(y = data1$Churn, p= 0.80, list = FALSE)
train <- data1[intrain,]
test <- data1[-intrain,]

```

# Variable Selection (Based on EDA)
```{r}
train1 <- train[,-c(24:26)]
train_part1 <- train[,c(1:5,27)]
train_part2 <- train[,c(1:15,27)]
train_part3 <- train[,c(1:5,16:27)]
train_part4 <- train[,c(1:5,7,16:22,24,26,27)]
train_part5 <- train_part4[,-c(1,3,6,10,11)]
```

# upper level of correlation
```{r}
# get_upper_tri <- function(cortrain){
#   cortrain[lower.tri(cortrain)]<- NA
#   return(cortrain)
# }
# 
# upper_tri <- get_upper_tri(cortrain)

```

# Running model - logistic regression
```{r}
## First run a regression model with all variables for a quick check for multicollinearity
# logit <- glm(Churn ~ .,data=train1,family="binomial")
# summary(logit)
# car::vif(logit) # some variables show high multi...

# logit1 <- glm(Churn ~ .,data=train_part1,family="binomial")
# summary(logit1)
# 
# logit2 <- glm(Churn ~ .,data=train_part2,family="binomial")
# summary(logit2)
# 
# logit3 <- glm(Churn ~ .,data=train_part3,family="binomial")
# summary(logit3)
# 
# logit4 <- glm(Churn ~ .,data=train_part4,family="binomial")
# summary(logit4)
# 
# logit5 <- glm(Churn ~ .,data=train_part5,family="binomial")
# summary(logit5)

logit <- glm(Churn ~ .,data=train,family="binomial")
summary(logit)

a <- car::vif(logit)

kable(round(a,2))

# no multicollinearity
```



```{r}
# anova(logit_test, logit5)
# varImp(logit) # Variable Importance
# 
# # install.packages("pscl")
# # library(pscl)
# # pR2(logit5)
```

```{r}
fitted.results <- predict(logit,newdata=test,type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)

misClasificError <- mean(fitted.results != test$Churn)
print(paste('Accuracy',1-misClasificError))

# 
# fitted.results2 <- predict(logit2,newdata=subset(test,select=-c(1,3,14)),type='response')
# fitted.results2 <- ifelse(fitted.results2 > 0.5,1,0)
# 
# misClasificError2 <- mean(fitted.results2 != test$Churn)
# print(paste('Accuracy',1-misClasificError2))

```

```{r}
library(ROCR)
p <- predict(logit, newdata=test, type="response")
pr <- prediction(p, test$Churn)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)

auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc


# p2 <- predict(logit2, newdata=subset(test,select=-c(1,3,14)), type="response")
# pr2 <- prediction(p2, test$Churn)
# prf2 <- performance(pr2, measure = "tpr", x.measure = "fpr")
# plot(prf2)
# 
# auc2 <- performance(pr2, measure = "auc")
# auc2 <- auc2@y.values[[1]]
# auc2

```


